2024-01-28 02:27:45,869 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Current SDK version is 0.16.2
2024-01-28 02:27:45,869 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Configure stats pid to 3836
2024-01-28 02:27:45,869 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Loading settings from C:\Users\LENOVO\.config\wandb\settings
2024-01-28 02:27:45,869 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Loading settings from F:\backup-kali\Hackathons\ViduraAI\wandb\settings
2024-01-28 02:27:45,869 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-01-28 02:27:45,869 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'mlmodel\\train.py', 'program_abspath': 'f:\\backup-kali\\Hackathons\\ViduraAI\\mlmodel\\train.py', 'program': 'f:\\backup-kali\\Hackathons\\ViduraAI\\mlmodel\\train.py'}
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_init.py:_log_setup():526] Logging user logs to F:\backup-kali\Hackathons\ViduraAI\wandb\run-20240128_022745-cqngsu8h\logs\debug.log
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_init.py:_log_setup():527] Logging internal logs to F:\backup-kali\Hackathons\ViduraAI\wandb\run-20240128_022745-cqngsu8h\logs\debug-internal.log
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_init.py:init():566] calling init triggers
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_init.py:init():573] wandb.init called with sweep_config: {}
config: {'adafactor_beta1': None, 'adafactor_clip_threshold': 1.0, 'adafactor_decay_rate': -0.8, 'adafactor_eps': (1e-30, 0.001), 'adafactor_relative_step': True, 'adafactor_scale_parameter': True, 'adafactor_warmup_init': True, 'adam_betas': (0.9, 0.999), 'adam_epsilon': 1e-08, 'best_model_dir': 'outputs/bert/best_model', 'cache_dir': 'cache_dir/', 'config': {}, 'cosine_schedule_num_cycles': 0.5, 'custom_layer_parameters': [], 'custom_parameter_groups': [], 'dataloader_num_workers': 0, 'do_lower_case': False, 'dynamic_quantize': False, 'early_stopping_consider_epochs': False, 'early_stopping_delta': 0, 'early_stopping_metric': 'correct', 'early_stopping_metric_minimize': False, 'early_stopping_patience': 3, 'encoding': None, 'eval_batch_size': 64, 'evaluate_during_training': True, 'evaluate_during_training_silent': True, 'evaluate_during_training_steps': 1000, 'evaluate_during_training_verbose': False, 'evaluate_each_epoch': True, 'fp16': False, 'gradient_accumulation_steps': 1, 'learning_rate': 1e-05, 'local_rank': -1, 'logging_steps': 50, 'loss_type': None, 'loss_args': {}, 'manual_seed': None, 'max_grad_norm': 1.0, 'max_seq_length': 128, 'model_name': 'bert-base-cased', 'model_type': 'bert', 'multiprocessing_chunksize': -1, 'n_gpu': 1, 'no_cache': False, 'no_save': False, 'not_saved_args': [], 'num_train_epochs': 5, 'optimizer': 'AdamW', 'output_dir': 'outputs/bert', 'overwrite_output_dir': True, 'polynomial_decay_schedule_lr_end': 1e-07, 'polynomial_decay_schedule_power': 1.0, 'process_count': 6, 'quantized_model': False, 'reprocess_input_data': True, 'save_best_model': True, 'save_eval_checkpoints': False, 'save_model_every_epoch': False, 'save_optimizer_and_scheduler': True, 'save_steps': 2000, 'scheduler': 'linear_schedule_with_warmup', 'silent': False, 'skip_special_tokens': True, 'tensorboard_dir': None, 'thread_count': None, 'tokenizer_name': None, 'tokenizer_type': None, 'train_batch_size': 32, 'train_custom_parameters_only': False, 'use_cached_eval_features': False, 'use_early_stopping': False, 'use_hf_datasets': False, 'use_multiprocessing': True, 'use_multiprocessing_for_evaluation': True, 'wandb_kwargs': {'name': 'bert-base-cased'}, 'wandb_project': 'Question Answering using BERT', 'warmup_ratio': 0.06, 'warmup_steps': 1, 'weight_decay': 0.0, 'model_class': 'QuestionAnsweringModel', 'doc_stride': 384, 'lazy_loading': False, 'max_answer_length': 100, 'max_query_length': 64, 'n_best_size': 3, 'null_score_diff_threshold': 0.0, 'special_tokens_list': []}
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_init.py:init():616] starting backend
2024-01-28 02:27:45,887 INFO    MainThread:3836 [wandb_init.py:init():620] setting up manager
2024-01-28 02:27:45,889 INFO    MainThread:3836 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn, using: spawn
2024-01-28 02:27:45,891 INFO    MainThread:3836 [wandb_init.py:init():628] backend started and connected
2024-01-28 02:27:45,894 INFO    MainThread:3836 [wandb_init.py:init():720] updated telemetry
2024-01-28 02:27:45,969 INFO    MainThread:3836 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-01-28 02:27:47,088 INFO    MainThread:3836 [wandb_run.py:_on_init():2254] communicating current version
2024-01-28 02:27:47,571 INFO    MainThread:3836 [wandb_run.py:_on_init():2263] got version response 
2024-01-28 02:27:47,571 INFO    MainThread:3836 [wandb_init.py:init():804] starting run threads in backend
2024-01-28 02:27:47,736 INFO    MainThread:3836 [wandb_run.py:_console_start():2233] atexit reg
2024-01-28 02:27:47,736 INFO    MainThread:3836 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2024-01-28 02:27:47,736 INFO    MainThread:3836 [wandb_run.py:_redirect():2153] Wrapping output streams.
2024-01-28 02:27:47,736 INFO    MainThread:3836 [wandb_run.py:_redirect():2178] Redirects installed.
2024-01-28 02:27:47,736 INFO    MainThread:3836 [wandb_init.py:init():847] run started, returning control to user process
2024-01-28 02:27:47,736 INFO    MainThread:3836 [wandb_watch.py:watch():51] Watching
2024-01-28 02:27:58,443 WARNING MsgRouterThr:3836 [router.py:message_loop():77] message_loop has been closed
